# CDFM: Training-Free Co-Optimized Conditional Diffusion Model for General Image Fusion

> **Note**: The source code for this work will be open-sourced upon paper acceptance.

This repository is reserved for the official implementation of our paper:  
**"CDFM: Training-Free Co-Optimized Conditional Diffusion Model for General Image Fusion"**  
Submitted to Information Fusion

---

## ğŸ” About This Work
This study introduces CDFM, a training-free and general-purpose framework designed to eliminate task-specific training in image fusion.
---

## âœ… Our Track Record in Open-Sourcing

- **AU-Net** â€“ "AU-Net: Adaptive Unified Network for Joint Multi-modal Image Registration and Fusion" (IEEE TIP)  
  ğŸ“„ [Paper](https://doi.org/10.1109/TIP.2025.3586507) | ğŸ’» [Code](https://github.com/luming1314/AU-Net)  

- **LDRepFM** â€“ "LDRepFM: A Real-Time End-to-End Visible and Infrared Image Fusion Model Based on Layer Decomposition and Re-Parameterization" (IEEE TIM)  
  ğŸ“„ [Paper](https://github.com/luming1314/LDRepFM) | ğŸ’» [Code](https://github.com/luming1314/LDRepFM)  

---

## ğŸ“¬ Contact
For inquiries, please contact minglu@stu.jiangnan.edu.cn or visit [https://luming1314.github.io/](https://luming1314.github.io/).

---
